{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94c1041",
   "metadata": {},
   "source": [
    "# Tools for NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af2344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/Spark/spark-3.3.0-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066b59fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/23 12:01:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/23 12:01:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "830c2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, 'Hi I heard about Spark'),\n",
    "    (0.0, 'I wish Java could use case classes'),\n",
    "    (1.0, 'Logistic,Regression,models,are,neat'),\n",
    "    \n",
    "], ['label', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a87aa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            sentence|\n",
      "+-----+--------------------+\n",
      "|  0.0|Hi I heard about ...|\n",
      "|  0.0|I wish Java could...|\n",
      "|  1.0|Logistic,Regressi...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "sentenceData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b2f29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenzier = Tokenizer(inputCol='sentence', outputCol='words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bba4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data = tokenzier.transform(sentenceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "299e2092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            sentence|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|\n",
      "|  1.0|Logistic,Regressi...|[logistic,regress...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "327f8295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------+------------------------------------------+\n",
      "|label|sentence                           |words                                     |\n",
      "+-----+-----------------------------------+------------------------------------------+\n",
      "|0.0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |\n",
      "|0.0  |I wish Java could use case classes |[i, wish, java, could, use, case, classes]|\n",
      "|1.0  |Logistic,Regression,models,are,neat|[logistic,regression,models,are,neat]     |\n",
      "+-----+-----------------------------------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61feb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_tf = HashingTF(inputCol='words', outputCol='rawFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a52c6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurize_Data = hashing_tf.transform(words_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d49dc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol='rawFeatures', outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfa6646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_model = idf.fit(featurize_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "901dfb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_data = idf_model.transform(featurize_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11149705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/23 12:13:55 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "22/09/23 12:13:56 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                                                                                                      |\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0.0  |(262144,[18700,19036,33808,66273,173558],[0.6931471805599453,0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                                   |\n",
      "|0.0  |(262144,[19036,20719,55551,58672,98717,109547,192310],[0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])|\n",
      "|1.0  |(262144,[11534],[0.6931471805599453])                                                                                                                                                         |\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaled_data.select('label', 'features').show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c68968d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18b59350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (0, 'a b c'.split(' ')),\n",
    "    (1, 'a b b c a'.split(' ')),\n",
    "    \n",
    "], ['id', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e83384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "| id|          words|\n",
      "+---+---------------+\n",
      "|  0|      [a, b, c]|\n",
      "|  1|[a, b, b, c, a]|\n",
      "+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "447d4e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "| id|          words|\n",
      "+---+---------------+\n",
      "|  0|      [a, b, c]|\n",
      "|  1|[a, b, b, c, a]|\n",
      "+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68c09667",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol='words', outputCol='features', vocabSize=3, minDF=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31f626f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf61e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0ac5f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+-------------------------+\n",
      "|id |words          |features                 |\n",
      "+---+---------------+-------------------------+\n",
      "|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,2.0,1.0])|\n",
      "+---+---------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb241f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
